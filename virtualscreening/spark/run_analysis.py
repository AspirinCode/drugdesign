from pyspark import SparkContext, SparkConf
from pyspark.sql import SQLContext, Row	
import os
import operator
import ConfigParser as configparser
import ntpath
from vina_utils import get_file_name_sorted_energy, get_directory_pdbqt_analysis, get_files_pdbqt, get_directory_pdb_analysis, get_directory_complex_pdb_analysis, get_files_pdb, loading_pdb_2_list, get_name_receptor_pdb, save_model_receptor, get_name_model_pdb
from summary_statistics import get_summary_statistics, save_txt_summary_statistics
from pdbqt_io import split_pdbqt, pdbqt2pdb
from datetime import datetime

def save_analysis_log(finish_time, start_time):
	log_file_name = 'vs_analysis.log'
	current_path = os.getcwd()
	path_file = os.path.join(current_path, log_file_name)
	log_file = open(path_file, 'w')

	diff_time = finish_time - start_time
	msg = 'Starting ' + str(start_time) +'\n'
	log_file.write(msg)
	msg = 'Finishing ' + str(finish_time) +'\n'
	log_file.write(msg)
	msg = 'Time Execution (seconds): ' + str(diff_time.total_seconds()) +'\n'
	log_file.write(msg)


def main():

	sc = SparkContext()

	config = configparser.ConfigParser()
	config.read('config.ini')

	#Broadcast
	#Path that contains all files for analysis
	path_analysis = config.get('DEFAULT', 'path_analysis')
	#Path where all pdbqt files from VS are 
	path_save_structure = config.get('DEFAULT', 'path_save_structure')
	#Path where all pdb receptor are
	path_receptor_pdb = config.get('DEFAULT', 'pdb_path')	
	#Path for saving pdbqt files that are splited from VS
	path_analysis_pdbqt = get_directory_pdbqt_analysis(path_analysis)
	#Path for saving pdb files of models generated by VS
	path_analysis_pdb = get_directory_pdb_analysis(path_analysis)
	#Path for saving complex pdb files of models and receptor
	path_analysis_pdb_complex = get_directory_complex_pdb_analysis(path_analysis)
	#Path for drugdesign project
	path_spark_drugdesign = config.get('DRUGDESIGN', 'path_spark_drugdesign')
	#Runing MGLTools for pdbqt to pdb
	pythonsh       = config.get('VINA', 'pythonsh')
	script_pdbqt_to_pdb = config.get('VINA', 'script_pdbqt_to_pdb')	

	#Adding Python Source file
	sc.addPyFile(os.path.join(path_spark_drugdesign,"vina_utils.py"))
	sc.addPyFile(os.path.join(path_spark_drugdesign,"summary_statistics.py"))
	sc.addPyFile(os.path.join(path_spark_drugdesign,"pdbqt_io.py"))

	start_time = datetime.now()

	#File that contains sorted energies from all log file
	energy_file_name = os.path.join(path_analysis,get_file_name_sorted_energy())

	text_file = sc.textFile(energy_file_name)

	#Spliting energy file by \t
	rdd_vs_energies_sorted_split = text_file.map(lambda line: line.split("\t"))
	rdd_vs_energies_sorted = rdd_vs_energies_sorted_split.map(lambda p: Row(name=str(p[0]), mode=int(p[1]), energy=float(p[2]) ))

	# Appling Summary and Descriptive Statistics in Energies
	summary_statistics_out = get_summary_statistics(sc, rdd_vs_energies_sorted)
	save_txt_summary_statistics(path_analysis, summary_statistics_out)

	#Creating model pdbqt files from VS structures 
	list_pdbqt_model = []
	all_structures = get_files_pdbqt(path_save_structure)
	for structure in all_structures:
		list_pdbqt_model.append( (structure, path_analysis_pdbqt) )
	
	pdbqtRDD = sc.parallelize(list_pdbqt_model)	
	pdbqtRDD.foreach(split_pdbqt)

	#Creating pdb files from model pdbqt files
	list_pdb_model = []
	all_models = get_files_pdbqt(path_analysis_pdbqt)
	for model in all_models:
		list_pdb_model.append( (model, path_analysis_pdb, pythonsh, script_pdbqt_to_pdb) )
	
	pdb_modelRDD = sc.parallelize(list_pdb_model)	
	pdb_modelRDD.foreach(pdbqt2pdb)

	#Creating complex: receptor+pdb_model.pdb

	#Loading all PDB receptor files into memory
	list_all_pdb_receptor_files_path = []
	all_receptor_for_complex = get_files_pdb(path_receptor_pdb)
	for receptor in all_receptor_for_complex:
		list_all_pdb_receptor_files_path.append(loading_pdb_2_list(receptor))

	#Loading all PDB model files into memory
	all_model_for_complex = get_files_pdb(path_analysis_pdb)
	all_model_for_complexRDD = sc.parallelize(all_model_for_complex)
	all_model_filesRDD = all_model_for_complexRDD.map(loading_pdb_2_list).collect()
	all_model_filesRDD	= sc.parallelize(all_model_filesRDD)

	for pdb_receptor_files in list_all_pdb_receptor_files_path:
		#Getting receptor name by fully path
		base_file_name_receptor = get_name_receptor_pdb(str(pdb_receptor_files[0]))
		#PDB file loaded into memory is sent by broadcast
		pdb_file_receptor = pdb_receptor_files[1]		
		#Filter all models based on name of receptor				
		pdb_model_file_filter_recepRDD = all_model_filesRDD.filter(lambda x: str(x[0]).find(base_file_name_receptor) > -1 ).collect()
		#Starting the paralelization of building complex
		list_all_receptor_model_file = []
		for model in pdb_model_file_filter_recepRDD:
			base_name_model = get_name_model_pdb(model[0])
			complex_name = "compl_"+base_name_model+".pdb"
			full_path_for_save_complex = os.path.join(path_analysis_pdb_complex,complex_name)
			list_all_receptor_model_file.append( (pdb_file_receptor, model[1], full_path_for_save_complex) )
		pdb_model_file_filter_recepRDD = sc.parallelize(list_all_receptor_model_file)				
		pdb_model_file_filter_recepRDD.foreach(save_model_receptor)
	
	finish_time = datetime.now()

	save_analysis_log(finish_time, start_time)

main()